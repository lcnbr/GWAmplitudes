# Introduction {#sec-intro}

The detection of (?s:gw) by the (?:ligo) and Virgo collaborations in 2016 [-@LIGOScientific:2016aoc] has sparked a new era of (?:gw) astronomy. The first detections were of (?:bbh) mergers. More recently, (?:bns)  mergers [-@LIGOScientific:2017vwq]  as well as (?:nsbh) mergers have been detected [-@LIGOScientific:2021qlt]. Future observatories will further increase sensitivity and will be able to detect a wide range of astrophysical sources. Studying these (?s:gw) signals gives us a very powerful new window into the universe.  It allows us to study the properties of neutron stars and black holes, and the physics of compact object mergers, but also gives us a powerful testing apparatus for general relativity.

To detect these faint signals (?:ligo) and Virgo have been made to be extraordinarily sensitive instruments. This sensitivity had been the main barrier to overcome ever since (?:gw) were first predicted by Einstein. Whilst sensitive measurements generally demand, and thus drive equally precise theoretical predictions, for (?:gw) astronomy, the case for theoretical models is even stronger. Indeed, theoretical models are necessary components to the detection mechanisms used at current laser interferometers. The faint signals of strain due to the passage of a (?:gw) are often buried in the noise of the detector. To counteract this, experimental physicists make use of matched filtering, an approach where a template signal is cross correlated to the detector output. The template is a model of the signal provided by theoretical physicists based on physical models. The upper bound to physical content of the detection is thus in fact set by the physical content of the template and therefore of the theoretical model. Additionally, the more precise the template, the higher the signal-to-noise ratio, the more probable and precise the detection. Theoretical models are thus a crucial component of the detection process, and there is a strong incentive to improve their precision and breadth of applicability.

In recent years, an unlikely ally in this precision race has arisen, based on (?:qft) techniques [@Goldberger:2004jt,@Kosower:2018adc,@Porto:2016pyg,@Neill:2013wsa]. This is seemingly an impossibility as (?:qft) and (?:gr) have historically been the two irreconcilable theories that 'together' span the whole range of scales in the universe. (?:qft) and the standard model, describe physics at the smallest scales, where quantum effects dominate. This is the physics of colliders, and condensed matter. The standard model is our best guess as to the nature of the fundamental constituents of 'matter' and 'light'. 

(?:gr) on the other hand describes physics at the largest scales, where gravity dominates. It was developed by Einstein as the successor to the Newtonian theory of gravity, which was not able to account for orbital mechanics such as the precession of the perihelion of mercury. Having passed every experimental test we have thrown at it, (?:gr) is by far the best theory of gravity we have yet. It can describe cosmological phenomena, as well as the compact objects known as black holes.

These two physics leviathans do not get along, unfortunately. (?:gr) is a theory of geometry, and (?:qft) is a theory of interactions. We can try to write and interpret one in the language of the other, but in either case difficulties arise. Writing (?:gr) in terms of perturbative (?:qft) one introduces the graviton, the spin 2 quantum of gravity. Disappointingly, such a theory breaks down at high energies, and is un-renormalisable . In fact the presence of black holes, that dominate the high energy spectrum of (?:gr), is a testament to that fact   [@Shomer:2007vq]. On the other hand, whilst one can write (?s:qft) on a curved background, this does not quantize gravity itself, and therefore does not really address the problem. Background independent theories such as loop quantum gravity does not yet have semiclassical limit collapsing to (?:gr). String theory, on the other hand, introduces spurious dimensions that need to be compactified, which leads to uncountably many solutions. In short, there is no satisfactory theory of that combines (?:gr) and (?:qft) consistently. 

Surprisingly, one can still use the powerful tools of one theory to tackle problems in the other. Specifically,  considering the classical limit of (?:qft), allows the extraction of perturbative gravitational dynamics from an initially quantum description of the setup. This is interesting because the tools developed for high energy physics have become extremely powerful and efficient theoretical machines, often making use of diagrammatic reasoning. Tools such as Feynman diagrams, differential equations [@Remiddi:1997ny,@Bern:1993kr,@Kotikov:1990kg] and more recently generalized unitarity [@Bern:1994cg,@Bern:2004ky,@Buchbinder:2005wp,@Anastasiou:2006jv], all yielding efficient computations for scattering amplitudes, can all be applied to *classical* orbital dynamics in (?:gr). This is exactly the subject of this thesis.

Specifically we are interested in the diagrammatic objects that arise when framing the two body problem similarly to particle collisions. Diagrammatics are interesting as they are an abstraction of the problem that enables efficient reasoning about and automation of the solutions. We will explain where these tools shine in the broader context of waveform approaches such as (?:eob) , (?:nrgr) , (?:pm) and (?:pn) approximations. 

This thesis is organized as follows. In  [@sec-gwgen] we deal with the theoretical foundations of (?s:gw), exploring how they arise through the linearized Einsteins' field equations. The subsequent [@sec-gwdetect] discusses the experimental apparatuses that are used to detect (?s:gw). We describe at the techniques used to extract the signals from the noise, and motivate precise theoretical predictions. In @sec-wfgen we look at how to generate partial and full waveforms. We explore the (?:eob) and (?:nr) frameworks. Motivated by the need for more precise ingredients to input into (?:eob), in @sec-scat we explain the state of the art formalisms that incorporate amplitude tools into the program. We describe the conservative (?:eft) matching approach, where the system does not lose energy to its environement. Taking into account the loss of energy due to (?s:gw) necesitates another method: the (?:kmoc) formalism, which makes up the second half of the chapter. In this context, we take a deeper look at amplitude computing tools. We conclude with a discussion of the challenges that lie ahead, and the future of (?:gw) astronomy.

